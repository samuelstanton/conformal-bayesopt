{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import botorch\n",
    "\n",
    "sns.set(style='whitegrid', font_scale=1.75)\n",
    "\n",
    "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ac8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsort\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from experiments.std_bayesopt.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000695d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fn = lambda x: np.maximum(-0.125 * x ** 2 + 16 * np.sin(x), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285531e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "noise_scale = 1.\n",
    "x_bounds = torch.tensor((-16., 16.)).view(-1, 1)\n",
    "\n",
    "x = np.linspace(*x_bounds, 64)\n",
    "f = obj_fn(x)\n",
    "y = f + noise_scale * np.random.randn(*f.shape)\n",
    "\n",
    "plt.scatter(x, y, edgecolors='black', facecolors='none', label='observations', s=64, zorder=3)\n",
    "plt.plot(x, f, color='black', linestyle='--', label='ground truth', linewidth=2, zorder=2)\n",
    "\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "plt.ylim((-4, 24))\n",
    "plt.legend(loc='upper left', ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botorch\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.sampling import IIDNormalSampler\n",
    "\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33012561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambo.utils import DataSplit, update_splits\n",
    "from lambo.optimizers.pymoo import Normalizer\n",
    "\n",
    "cutoff = np.max(np.where(x < -8))\n",
    "x_min, y_min = x.min(0), y.min(0)\n",
    "x_range, y_range = x.max(0) - x_min, y.max(0) - y_min\n",
    "\n",
    "x_norm = Normalizer(\n",
    "    loc=x_min + 0.5 * x_range,\n",
    "    scale=x_range / 2.,\n",
    ")\n",
    "y_norm = Normalizer(\n",
    "    loc=y_min + 0.5 * y_range,\n",
    "    scale=y_range / 2.,\n",
    ")\n",
    "\n",
    "train_x = x[:cutoff]\n",
    "train_y = y[:cutoff]\n",
    "\n",
    "all_inputs = torch.tensor(x_norm(x), device=DEVICE).view(-1, 1)\n",
    "all_targets = torch.tensor(y_norm(y), device=DEVICE).view(-1, 1)\n",
    "target_dim = all_targets.shape[-1]\n",
    "\n",
    "new_split = DataSplit(\n",
    "    all_inputs[:cutoff].cpu().numpy(), all_targets[:cutoff].cpu().numpy()\n",
    ")\n",
    "train_split, val_split, test_split = update_splits(\n",
    "    train_split=DataSplit(),\n",
    "    val_split=DataSplit(),\n",
    "    test_split=DataSplit(),\n",
    "    new_split=new_split,\n",
    "    holdout_ratio=0.2\n",
    ")\n",
    "\n",
    "cls_train_split, cls_val_split, cls_test_split = update_splits(\n",
    "    train_split=DataSplit(),\n",
    "    val_split=DataSplit(),\n",
    "    test_split=DataSplit(),\n",
    "    new_split=DataSplit(),\n",
    "    holdout_ratio=0.2\n",
    ")\n",
    "\n",
    "input_bounds = torch.tensor([-1., 1.], device=DEVICE).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_datashift_opt(splits, cls_splits=None, acqf=\"ei\"):\n",
    "    def draw_plot(ax):\n",
    "        # plot p(f | x, D)\n",
    "        ax.plot(all_inputs.cpu(), f_hat_mean, color='blue', linewidth=2, zorder=4, label='p(f | x, D)')\n",
    "        ax.fill_between(all_inputs.view(-1).cpu(), f_hat_mean - 1.96 * f_hat_std, f_hat_mean + 1.96 * f_hat_std,\n",
    "                        color='blue', alpha=0.25)\n",
    "\n",
    "        # plot a(x)\n",
    "        ax.plot(all_inputs.cpu(), acq_vals, color='green', zorder=5, linewidth=2, label='a(x)')\n",
    "        ax.scatter(input_query.cpu(), target_query.cpu(), marker='x', color='red', label='x*', zorder=5,\n",
    "                   s=32, linewidth=2)\n",
    "\n",
    "        # plot observed\n",
    "        ax.scatter(train_inputs.cpu(), train_targets.cpu(), edgecolors='black', facecolors='black',\n",
    "                   label='D', s=32, zorder=3)\n",
    "\n",
    "        # plot true function\n",
    "        ax.plot(all_inputs.cpu(), y_norm(f), color='black', linestyle='--', label='f')\n",
    "\n",
    "        ax.set_ylim((-2., 2.))\n",
    "\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        return ax\n",
    "\n",
    "    train_split, val_split, test_split = splits\n",
    "    \n",
    "    optimize_callback = None\n",
    "    rx_estimator = None\n",
    "    if acqf == 'ei':\n",
    "        acqf_init = lambda gp, best_f: qExpectedImprovement(\n",
    "            gp,\n",
    "            best_f=train_targets.max(0)[0],\n",
    "            sampler=IIDNormalSampler(64)\n",
    "        )\n",
    "    elif acqf == \"nei\":\n",
    "        acqf_init = lambda gp, best_f: qNoisyExpectedImprovement(gp, X_baseline=train_inputs, sampler=IIDNormalSampler(64))\n",
    "    elif acqf == 'conformal_ei':\n",
    "        def acqf_init(gp, best_f):\n",
    "            gp.conformal()\n",
    "            return qConformalExpectedImprovement(\n",
    "                gp,\n",
    "                best_f=train_targets.max(0)[0],\n",
    "                sampler=PassSampler(32),\n",
    "                cache_root=False\n",
    "            )\n",
    "\n",
    "        ######### Ratio Estimator ###########\n",
    "        cls_train_split, cls_val_split, cls_test_split = cls_splits\n",
    "\n",
    "        ## Remains uniform, when untrained.\n",
    "        classifier = nn.Sequential(\n",
    "            nn.Linear(train_split.inputs.shape[-1], 1),\n",
    "        ).to(DEVICE)\n",
    "        for p in classifier.parameters():\n",
    "            p.data.fill_(0)\n",
    "        optim = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        class _RatioEstimator(nn.Module):\n",
    "            def forward(self, inputs):\n",
    "                _p = classifier(inputs).squeeze(-1).sigmoid()\n",
    "                ## FIXME: adjust for class priors?\n",
    "                return _p / (1 - _p + 1e-6)\n",
    "        rx_estimator = _RatioEstimator()\n",
    "\n",
    "        class RatioDataset(torch.utils.data.Dataset):\n",
    "            def __len__(self):\n",
    "                return len(cls_train_split.inputs)\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                return cls_train_split.inputs[index], cls_train_split.targets[index]\n",
    "        rx_dataset = RatioDataset()\n",
    "\n",
    "        def optimize_callback(xk):\n",
    "            global cls_train_split, cls_val_split, cls_test_split\n",
    "\n",
    "            ## FIXME: handle too many -ve samples.\n",
    "            xk = torch.from_numpy(xk).reshape(-1, 1)\n",
    "            xk.add_(.1 * torch.randn_like(xk))\n",
    "            yk = torch.zeros(len(xk), 1)\n",
    "            cls_train_split, cls_val_split, cls_test_split = update_splits(\n",
    "                train_split=cls_train_split,\n",
    "                val_split=cls_val_split,\n",
    "                test_split=cls_test_split,\n",
    "                new_split=DataSplit(xk, yk),\n",
    "                holdout_ratio=0.2\n",
    "            )\n",
    "\n",
    "            ## One stochastic gradient step of the classifier.\n",
    "            if len(rx_dataset):\n",
    "                loader = torch.utils.data.DataLoader(rx_dataset, shuffle=True, batch_size=64)\n",
    "                X, y = next(iter(loader))\n",
    "                X, y = X.to(DEVICE).float(), y.to(DEVICE)\n",
    "                optim.zero_grad()\n",
    "                loss = criterion(classifier(X), y)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "        ######### Ratio Estimator ###########\n",
    "    elif acqf == \"conformal_nei\":\n",
    "        def acqf_init(gp, best_f):\n",
    "            gp.conformal()\n",
    "            return qConformalNoisyExpectedImprovement(\n",
    "                gp,\n",
    "                X_baseline=train_inputs,\n",
    "                sampler=PassSampler(32),\n",
    "                cache_root=False\n",
    "            )\n",
    "        \n",
    "    num_rounds = 32\n",
    "    plot_interval = 8\n",
    "    \n",
    "    queried_targets = []\n",
    "    for round_idx in range(num_rounds):\n",
    "        train_inputs = torch.tensor(train_split[0], device=DEVICE)\n",
    "        train_targets = torch.tensor(train_split[1], device=DEVICE)\n",
    "\n",
    "        matern_gp = ConformalSingleTaskGP(\n",
    "            train_X=train_inputs,\n",
    "            train_Y=train_targets,\n",
    "            alpha=0.1,\n",
    "            tgt_grid_res=32,\n",
    "            conformal_bounds=torch.tensor([[-2., 2.]]).t(),\n",
    "            ratio_estimator=rx_estimator,\n",
    "        ).to(DEVICE)\n",
    "        mll = ExactMarginalLogLikelihood(matern_gp.likelihood, matern_gp)\n",
    "        fit_gpytorch_model(mll)\n",
    "        # acq_fn = UpperConfidenceBound(matern_gp, beta=8.)\n",
    "        # HERE WE USE EI\n",
    "        # acq_fn = ExpectedImprovement(matern_gp, best_f=train_targets.max())\n",
    "        acq_fn = acqf_init(matern_gp, train_targets.max())\n",
    "\n",
    "        matern_gp.requires_grad_(False)\n",
    "        matern_gp.eval()\n",
    "        with torch.no_grad():\n",
    "            f_hat_dist = matern_gp(all_inputs)\n",
    "            y_hat_dist = matern_gp.likelihood(f_hat_dist)\n",
    "            f_hat_mean = f_hat_dist.mean.cpu()\n",
    "            f_hat_std = f_hat_dist.variance.sqrt().cpu()\n",
    "            y_hat_mean = f_hat_mean.cpu()\n",
    "            y_hat_std = y_hat_dist.variance.sqrt().cpu()\n",
    "            acq_vals = acq_fn(all_inputs[:, None]).cpu()\n",
    "\n",
    "        input_query = optimize_acqf(acq_fn, input_bounds, 1, num_restarts=4, raw_samples=16,\n",
    "                                    options=dict(callback=optimize_callback))[0]\n",
    "        x_query = x_norm.inv_transform(input_query.cpu().numpy())\n",
    "        f_query = obj_fn(x_query)\n",
    "        y_query = f_query + noise_scale * np.random.randn(*f_query.shape)\n",
    "        target_query = torch.tensor(y_norm(y_query), device=DEVICE)\n",
    "\n",
    "        new_split = DataSplit(\n",
    "            input_query.reshape(-1, 1).cpu(),\n",
    "            target_query.reshape(-1, 1).cpu(),\n",
    "        )\n",
    "        train_split, val_split, test_split = update_splits(\n",
    "            train_split, val_split, test_split, new_split, holdout_ratio=0.2\n",
    "        )\n",
    "        if acqf.startswith('conformal'):\n",
    "            cls_train_split, cls_val_split, cls_test_split = update_splits(\n",
    "                train_split=cls_train_split,\n",
    "                val_split=cls_val_split,\n",
    "                test_split=cls_test_split,\n",
    "                new_split=DataSplit(\n",
    "                    input_query.reshape(-1, 1).cpu(),\n",
    "                    torch.ones(1, 1),\n",
    "                ),\n",
    "                holdout_ratio=0.2\n",
    "            )\n",
    "\n",
    "        queried_targets.append(target_query)\n",
    "\n",
    "        if round_idx % plot_interval == 0:\n",
    "            print(f'{train_split[0].shape[0]} train, {val_split[0].shape[0]} val, {test_split[0].shape[0]} test')\n",
    "            if acqf.startswith('conformal'):\n",
    "                print(f'[Iterates] {cls_train_split[0].shape[0]} train, {cls_val_split[0].shape[0]} val, {cls_test_split[0].shape[0]} test')\n",
    "            fig = plt.figure(figsize=(8, 5))\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            draw_plot(ax)\n",
    "\n",
    "    plt.show()\n",
    "    return torch.tensor(queried_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f91447",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_pts = [\n",
    "    run_datashift_opt([train_split, val_split, test_split],\n",
    "                      [cls_train_split, cls_val_split, cls_test_split],\n",
    "                      acqf=\"conformal_ei\") for _ in range(2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf145d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pts = [run_datashift_opt([train_split, val_split, test_split], acqf=\"ei\") for _ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b4cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal = torch.stack(conformal_pts).cummax(1)[0]\n",
    "std = torch.stack(std_pts).cummax(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(conformal.mean(0), label = \"conformal qEI\")\n",
    "plt.fill_between(torch.arange(32), \n",
    "                 conformal.mean(0) - 2. / 5**0.5 * conformal.std(0), \n",
    "                 conformal.mean(0) + 2. / 5**0.5 * conformal.std(0), \n",
    "                 alpha = 0.3)\n",
    "plt.plot(std.mean(0), label = \"qEI\")\n",
    "plt.fill_between(torch.arange(32), \n",
    "                 std.mean(0) - 2. / 5**0.5 * std.std(0), \n",
    "                 std.mean(0) + 2. / 5**0.5 * std.std(0), \n",
    "                 alpha = 0.3)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Function Evaluations\")\n",
    "plt.ylabel(\"Best Achieved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
