{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import botorch\n",
    "\n",
    "sns.set(style='whitegrid', font_scale=1.75)\n",
    "\n",
    "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ac8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsort\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from experiments.std_bayesopt.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000695d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fn = lambda x: np.maximum(-0.125 * x ** 2 + 16 * np.sin(x), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285531e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "noise_scale = 1.\n",
    "x_bounds = torch.tensor((-16., 16.)).view(-1, 1)\n",
    "\n",
    "x = np.linspace(*x_bounds, 64)\n",
    "f = obj_fn(x)\n",
    "y = f + noise_scale * np.random.randn(*f.shape)\n",
    "\n",
    "plt.scatter(x, y, edgecolors='black', facecolors='none', label='observations', s=64, zorder=3)\n",
    "plt.plot(x, f, color='black', linestyle='--', label='ground truth', linewidth=2, zorder=2)\n",
    "\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "plt.ylim((-4, 24))\n",
    "plt.legend(loc='upper left', ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botorch\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.sampling import IIDNormalSampler\n",
    "\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33012561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambo.utils import DataSplit, update_splits, safe_np_cat\n",
    "from lambo.optimizers.pymoo import Normalizer\n",
    "\n",
    "cutoff = np.max(np.where(x < -8))\n",
    "x_min, y_min = x.min(0), y.min(0)\n",
    "x_range, y_range = x.max(0) - x_min, y.max(0) - y_min\n",
    "\n",
    "x_norm = Normalizer(\n",
    "    loc=x_min + 0.5 * x_range,\n",
    "    scale=x_range / 2.,\n",
    ")\n",
    "y_norm = Normalizer(\n",
    "    loc=y_min + 0.5 * y_range,\n",
    "    scale=y_range / 2.,\n",
    ")\n",
    "\n",
    "train_x = x[:cutoff]\n",
    "train_y = y[:cutoff]\n",
    "\n",
    "all_inputs = torch.tensor(x_norm(x), device=DEVICE).view(-1, 1)\n",
    "all_targets = torch.tensor(y_norm(y), device=DEVICE).view(-1, 1)\n",
    "target_dim = all_targets.shape[-1]\n",
    "\n",
    "new_split = DataSplit(\n",
    "    all_inputs[:cutoff].cpu().numpy(), all_targets[:cutoff].cpu().numpy()\n",
    ")\n",
    "train_split, val_split, test_split = update_splits(\n",
    "    train_split=DataSplit(),\n",
    "    val_split=DataSplit(),\n",
    "    test_split=DataSplit(),\n",
    "    new_split=new_split,\n",
    "    holdout_ratio=0.2\n",
    ")\n",
    "\n",
    "input_bounds = torch.tensor([-1., 1.], device=DEVICE).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_datashift_opt(splits, acqf=\"ei\"):\n",
    "    def draw_plot(ax):\n",
    "        # plot p(f | x, D)\n",
    "        ax.plot(all_inputs.cpu(), f_hat_mean, color='blue', linewidth=2, zorder=4, label='p(f | x, D)')\n",
    "        ax.fill_between(all_inputs.view(-1).cpu(), f_hat_mean - 1.96 * f_hat_std, f_hat_mean + 1.96 * f_hat_std,\n",
    "                        color='blue', alpha=0.25)\n",
    "\n",
    "        # plot a(x)\n",
    "        ax.plot(all_inputs.cpu(), acq_vals, color='green', zorder=5, linewidth=2, label='a(x)')\n",
    "        ax.scatter(input_query.cpu(), target_query.cpu(), marker='x', color='red', label='x*', zorder=5,\n",
    "                   s=32, linewidth=2)\n",
    "\n",
    "        # plot observed\n",
    "        ax.scatter(train_inputs.cpu(), train_targets.cpu(), edgecolors='black', facecolors='black',\n",
    "                   label='D', s=32, zorder=3)\n",
    "\n",
    "        # plot true function\n",
    "        ax.plot(all_inputs.cpu(), y_norm(f), color='black', linestyle='--', label='f')\n",
    "\n",
    "        ax.set_ylim((-2., 2.))\n",
    "\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        return ax\n",
    "\n",
    "    train_split, val_split, test_split = splits\n",
    "    \n",
    "    rx_estimator = None\n",
    "    optimize_callback = None\n",
    "\n",
    "    if acqf == 'ei':\n",
    "        acqf_init = lambda gp, best_f: qExpectedImprovement(\n",
    "            gp,\n",
    "            best_f=train_targets.max(0)[0],\n",
    "            sampler=IIDNormalSampler(64)\n",
    "        )\n",
    "    elif acqf == \"nei\":\n",
    "        acqf_init = lambda gp, best_f: qNoisyExpectedImprovement(gp, X_baseline=train_inputs, sampler=IIDNormalSampler(64))\n",
    "    elif acqf == 'conformal_ei':\n",
    "        def acqf_init(gp, best_f):\n",
    "            gp.conformal()\n",
    "            return qConformalExpectedImprovement(\n",
    "                gp,\n",
    "                best_f=train_targets.max(0)[0],\n",
    "                sampler=PassSampler(32),\n",
    "                cache_root=False\n",
    "            )\n",
    "\n",
    "        ######### Ratio Estimator ###########\n",
    "\n",
    "        class RatioEstimator(nn.Module):\n",
    "            class _Dataset(torch.utils.data.Dataset):\n",
    "                def __init__(self):\n",
    "                    self._prior_ratio = 1\n",
    "                    self.cls_train_split, self.cls_val_split, self.cls_test_split = update_splits(\n",
    "                        train_split=DataSplit(),\n",
    "                        val_split=DataSplit(),\n",
    "                        test_split=DataSplit(),\n",
    "                        new_split=DataSplit(),\n",
    "                        holdout_ratio=0.2\n",
    "                    )\n",
    "\n",
    "                def __len__(self):\n",
    "                    return len(self.cls_train_split.inputs)\n",
    "\n",
    "                def __getitem__(self, index):\n",
    "                    return self.cls_train_split.inputs[index], self.cls_train_split.targets[index]\n",
    "\n",
    "                @property\n",
    "                def emp_prior(self):\n",
    "                    return self._prior_ratio\n",
    "\n",
    "                def _recompute_emp_prior(self):\n",
    "                    _, train_targets = self.cls_train_split\n",
    "                    n = len(train_targets)\n",
    "                    n_p = train_targets.sum().item()\n",
    "                    if n_p > 0 and n > n_p:\n",
    "                        self._prior_ratio = n / n_p - 1.\n",
    "                    return self._prior_ratio\n",
    "\n",
    "                def _update_splits(self, new_split):\n",
    "                    self.cls_train_split, self.cls_val_split, self.cls_test_split = update_splits(\n",
    "                        train_split=self.cls_train_split,\n",
    "                        val_split=self.cls_val_split,\n",
    "                        test_split=self.cls_test_split,\n",
    "                        new_split=new_split,\n",
    "                        holdout_ratio=0.2)\n",
    "                    self._recompute_emp_prior()\n",
    "\n",
    "                def _drop_negative(self):\n",
    "                    _train_inputs, _train_targets = self.cls_train_split\n",
    "                    _val_inputs, _val_targets = self.cls_val_split\n",
    "                    _test_inputs, _test_targets = self.cls_test_split\n",
    "                    _inputs = safe_np_cat([_train_inputs, _val_inputs, _test_inputs], axis=0)\n",
    "                    _targets = safe_np_cat([_train_targets, _val_targets, _test_targets], axis=0)\n",
    "                    mask = np.squeeze(_targets > 0, axis=-1)\n",
    "                    _inputs, _targets = _inputs[mask, ...], _targets[mask, ...]\n",
    "                    \n",
    "                    self.cls_train_split, self.cls_val_split, self.cls_test_split = update_splits(\n",
    "                        train_split=DataSplit(),\n",
    "                        val_split=DataSplit(),\n",
    "                        test_split=DataSplit(),\n",
    "                        new_split=DataSplit(_inputs, _targets),\n",
    "                        holdout_ratio=0.2\n",
    "                    )\n",
    "\n",
    "                    self._recompute_emp_prior()\n",
    "\n",
    "            def __init__(self, in_size=1):\n",
    "                super().__init__()\n",
    "\n",
    "                self.dataset = RatioEstimator._Dataset()\n",
    "\n",
    "                ## Remains uniform, when untrained.\n",
    "                self.classifier = nn.Sequential(\n",
    "                    nn.Linear(in_size, 1),\n",
    "                )\n",
    "                for p in self.classifier.parameters():\n",
    "                    p.data.fill_(0)\n",
    "                    p.requires_grad_(True)\n",
    "\n",
    "                self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "                self.optim = torch.optim.Adam(self.classifier.parameters(), lr=1e-2)\n",
    "            \n",
    "            @torch.no_grad()\n",
    "            def forward(self, inputs):\n",
    "                _p = self.classifier(inputs).squeeze(-1).sigmoid()\n",
    "                return self.dataset.emp_prior * _p / (1 - _p + 1e-6)\n",
    "\n",
    "            def optimize_callback(self, xk):\n",
    "                xk = torch.from_numpy(xk).reshape(-1, 1)\n",
    "                xk.add_(.1 * torch.randn_like(xk))\n",
    "                yk = torch.zeros(len(xk), 1)\n",
    "\n",
    "                self.dataset._update_splits(DataSplit(xk, yk))\n",
    "\n",
    "                # NOTE: Need to set requires_grad.\n",
    "                for p in self.classifier.parameters():\n",
    "                    p.requires_grad_(True)\n",
    "\n",
    "                if len(self.dataset):\n",
    "                    loader = torch.utils.data.DataLoader(self.dataset, shuffle=True, batch_size=64)\n",
    "                    X, y = next(iter(loader))\n",
    "                    X, y = X.to(DEVICE).float(), y.to(DEVICE)\n",
    "                    self.optim.zero_grad()\n",
    "                    loss = self.criterion(self.classifier(X), y)\n",
    "                    loss.backward()\n",
    "                    self.optim.step()\n",
    "        \n",
    "        rx_estimator = RatioEstimator(in_size=train_split.inputs.shape[-1]).to(DEVICE)\n",
    "        optimize_callback = rx_estimator.optimize_callback\n",
    "        \n",
    "        ######### Ratio Estimator ###########\n",
    "    elif acqf == \"conformal_nei\":\n",
    "        def acqf_init(gp, best_f):\n",
    "            gp.conformal()\n",
    "            return qConformalNoisyExpectedImprovement(\n",
    "                gp,\n",
    "                X_baseline=train_inputs,\n",
    "                sampler=PassSampler(32),\n",
    "                cache_root=False\n",
    "            )\n",
    "        \n",
    "    num_rounds = 32\n",
    "    plot_interval = 8\n",
    "    \n",
    "    queried_targets = []\n",
    "    for round_idx in range(num_rounds):\n",
    "        train_inputs = torch.tensor(train_split[0], device=DEVICE)\n",
    "        train_targets = torch.tensor(train_split[1], device=DEVICE)\n",
    "\n",
    "        matern_gp = ConformalSingleTaskGP(\n",
    "            train_X=train_inputs,\n",
    "            train_Y=train_targets,\n",
    "            alpha=0.1,\n",
    "            tgt_grid_res=32,\n",
    "            conformal_bounds=torch.tensor([[-2., 2.]]).t(),\n",
    "            ratio_estimator=rx_estimator,\n",
    "        ).to(DEVICE)\n",
    "        mll = ExactMarginalLogLikelihood(matern_gp.likelihood, matern_gp)\n",
    "        fit_gpytorch_model(mll)\n",
    "        # acq_fn = UpperConfidenceBound(matern_gp, beta=8.)\n",
    "        # HERE WE USE EI\n",
    "        # acq_fn = ExpectedImprovement(matern_gp, best_f=train_targets.max())\n",
    "        acq_fn = acqf_init(matern_gp, train_targets.max())\n",
    "\n",
    "        matern_gp.requires_grad_(False)\n",
    "        matern_gp.eval()\n",
    "        with torch.no_grad():\n",
    "            f_hat_dist = matern_gp(all_inputs)\n",
    "            y_hat_dist = matern_gp.likelihood(f_hat_dist)\n",
    "            f_hat_mean = f_hat_dist.mean.cpu()\n",
    "            f_hat_std = f_hat_dist.variance.sqrt().cpu()\n",
    "            y_hat_mean = f_hat_mean.cpu()\n",
    "            y_hat_std = y_hat_dist.variance.sqrt().cpu()\n",
    "            acq_vals = acq_fn(all_inputs[:, None]).cpu()\n",
    "\n",
    "        input_query = optimize_acqf(acq_fn, input_bounds, 1, num_restarts=4, raw_samples=16,\n",
    "                                    options=dict(callback=optimize_callback))[0]\n",
    "        x_query = x_norm.inv_transform(input_query.cpu().numpy())\n",
    "        f_query = obj_fn(x_query)\n",
    "        y_query = f_query + noise_scale * np.random.randn(*f_query.shape)\n",
    "        target_query = torch.tensor(y_norm(y_query), device=DEVICE)\n",
    "\n",
    "        new_split = DataSplit(\n",
    "            input_query.reshape(-1, 1).cpu(),\n",
    "            target_query.reshape(-1, 1).cpu(),\n",
    "        )\n",
    "        train_split, val_split, test_split = update_splits(\n",
    "            train_split, val_split, test_split, new_split, holdout_ratio=0.2\n",
    "        )\n",
    "        if acqf.startswith('conformal'):\n",
    "            rx_estimator.dataset._update_splits(\n",
    "                DataSplit(input_query.reshape(-1, 1).cpu(), torch.ones(1, 1)))\n",
    "            rx_estimator.dataset._drop_negative()\n",
    "\n",
    "        queried_targets.append(target_query)\n",
    "\n",
    "        if round_idx % plot_interval == 0:\n",
    "            print(f'{train_split[0].shape[0]} train, {val_split[0].shape[0]} val, {test_split[0].shape[0]} test')\n",
    "            if acqf.startswith('conformal'):\n",
    "                print(f'[Iterates] {rx_estimator.dataset.cls_train_split[0].shape[0]} train, {rx_estimator.dataset.cls_val_split[0].shape[0]} val, {rx_estimator.dataset.cls_test_split[0].shape[0]} test')\n",
    "            fig = plt.figure(figsize=(8, 5))\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            draw_plot(ax)\n",
    "\n",
    "    plt.show()\n",
    "    return torch.tensor(queried_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f91447",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_pts = [run_datashift_opt([train_split, val_split, test_split], acqf=\"conformal_ei\") for _ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf145d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pts = [run_datashift_opt([train_split, val_split, test_split], acqf=\"ei\") for _ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b4cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal = torch.stack(conformal_pts).cummax(1)[0]\n",
    "std = torch.stack(std_pts).cummax(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(conformal.mean(0), label = \"conformal qEI\")\n",
    "plt.fill_between(torch.arange(32), \n",
    "                 conformal.mean(0) - 2. / 5**0.5 * conformal.std(0), \n",
    "                 conformal.mean(0) + 2. / 5**0.5 * conformal.std(0), \n",
    "                 alpha = 0.3)\n",
    "plt.plot(std.mean(0), label = \"qEI\")\n",
    "plt.fill_between(torch.arange(32), \n",
    "                 std.mean(0) - 2. / 5**0.5 * std.std(0), \n",
    "                 std.mean(0) + 2. / 5**0.5 * std.std(0), \n",
    "                 alpha = 0.3)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Function Evaluations\")\n",
    "plt.ylabel(\"Best Achieved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
