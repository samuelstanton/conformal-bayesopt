{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import botorch\n",
    "\n",
    "sns.set(style='whitegrid', font_scale=1.75)\n",
    "\n",
    "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "dtype = torch.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f5708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import botorch\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.acquisition.analytic import (\n",
    "    ExpectedImprovement,\n",
    "    NoisyExpectedImprovement,\n",
    "    UpperConfidenceBound,\n",
    ")\n",
    "from botorch.acquisition.monte_carlo import (\n",
    "    qExpectedImprovement,\n",
    "    qNoisyExpectedImprovement,\n",
    "    qUpperConfidenceBound,\n",
    ")\n",
    "from botorch.acquisition.knowledge_gradient import qKnowledgeGradient\n",
    "from botorch.acquisition.objective import IdentityMCObjective\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.sampling import IIDNormalSampler, SobolQMCNormalSampler\n",
    "from botorch.models import SingleTaskGP\n",
    "\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.constraints import Interval\n",
    "\n",
    "from conformalbo.ratio_estimation import RatioEstimator\n",
    "from conformalbo.helpers import (\n",
    "    assess_coverage,\n",
    "    construct_conformal_bands,\n",
    "    conf_mask_to_bounds,\n",
    ")\n",
    "from conformalbo.acquisitions import (\n",
    "    # conformalize_acq_fn,\n",
    "    qConformalKnowledgeGradient,\n",
    "    qConformalUpperConfidenceBound,\n",
    "    qConformalExpectedImprovement,\n",
    "    qConformalNoisyExpectedImprovement\n",
    ")\n",
    "\n",
    "from lambo.utils import DataSplit, update_splits\n",
    "from lambo.optimizers.pymoo import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000695d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fn = lambda x: np.maximum(0.25 * x - 0.125 * x ** 2 + 32 * np.cos(x), 0)\n",
    "\n",
    "noise_scale = 4.\n",
    "x_bounds = torch.tensor((-16., 16.), dtype=dtype).view(-1, 1)\n",
    "target_dim = 1\n",
    "input_bounds = torch.tensor([-1., 1.], device=DEVICE, dtype=dtype).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285531e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "x = np.linspace(*x_bounds, 128)\n",
    "f = obj_fn(x)\n",
    "y = f + noise_scale * np.random.randn(*f.shape)\n",
    "\n",
    "plt.scatter(x, y, edgecolors='black', facecolors='none', label='observations', s=64, zorder=2)\n",
    "plt.plot(x, f, color='black', linestyle='--', label='ground truth', linewidth=4, zorder=3)\n",
    "\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "# plt.ylim((-4, 24))\n",
    "# plt.legend(loc='upper left', ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2b7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x - x.min()) / (x.max() - x.min())\n",
    "f = (f - y.min()) / (y.max() - y.min())\n",
    "y = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "perm = np.random.permutation(x.size)\n",
    "train_inputs = torch.tensor(x[perm][:4], device=DEVICE, dtype=dtype).view(-1, 1)\n",
    "train_targets = torch.tensor(y[perm][:4], device=DEVICE, dtype=dtype).view(-1, 1)\n",
    "\n",
    "matern_gp = SingleTaskGP(\n",
    "    train_X=train_inputs,\n",
    "    train_Y=train_targets,\n",
    "    likelihood=GaussianLikelihood(noise_constraint=Interval(5e-2, 0.5)),\n",
    ").to(DEVICE)\n",
    "mll = ExactMarginalLogLikelihood(matern_gp.likelihood, matern_gp)\n",
    "fit_gpytorch_model(mll)\n",
    "matern_gp.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_grid_res = 16\n",
    "x1 = torch.linspace(0, 1, steps=q_grid_res, device=DEVICE, dtype=dtype)\n",
    "x2 = torch.linspace(0, 1, steps=q_grid_res, device=DEVICE, dtype=dtype)\n",
    "x1, x2 = torch.meshgrid(x1, x2, indexing='xy')\n",
    "x_grid = torch.stack([x1.reshape(-1), x2.reshape(-1)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff553c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_samples = 64\n",
    "\n",
    "sobol_eng = torch.quasirandom.SobolEngine(dimension=1)\n",
    "X_fantasy = sobol_eng.draw(mc_samples).to(x_grid)[np.random.permutation(mc_samples)]\n",
    "X_fantasy = X_fantasy.expand(x_grid.shape[0], -1, -1)\n",
    "# X_fantasy = torch.stack(\n",
    "#     [X_fantasy[np.random.permutation(mc_samples)] for _ in range(x_grid.shape[0])]\n",
    "# )\n",
    "kg_inputs = torch.cat([x_grid[..., None], X_fantasy], dim=-2)\n",
    "\n",
    "samples = sobol_eng.draw(mc_samples).view(-1)\n",
    "plt.scatter(samples, samples)\n",
    "plt.scatter(x_grid[:, 0].cpu(), x_grid[:, 1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_batch_dims = True\n",
    "\n",
    "sampler = IIDNormalSampler(mc_samples, collapse_batch_dims=collapse_batch_dims)\n",
    "# sampler = SobolQMCNormalSampler(mc_samples)\n",
    "\n",
    "inner_sampler = IIDNormalSampler(2 * mc_samples, collapse_batch_dims=collapse_batch_dims)\n",
    "# inner_sampler = SobolQMCNormalSampler(mc_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84fddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'qUCB'\n",
    "base_kwargs = dict(\n",
    "    model=matern_gp,\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "if base_name == 'qEI':\n",
    "    base_acq = qExpectedImprovement(\n",
    "        **base_kwargs,\n",
    "        best_f=f[perm][:4].max(),\n",
    "    )\n",
    "elif base_name == 'qNEI':\n",
    "    base_acq = qNoisyExpectedImprovement(\n",
    "        **base_kwargs,\n",
    "        X_baseline=train_inputs,\n",
    "    )\n",
    "elif base_name == 'qUCB':\n",
    "    base_acq = qUpperConfidenceBound(\n",
    "        **base_kwargs,\n",
    "        beta=1.,\n",
    "    )\n",
    "elif base_name == 'qKG':\n",
    "    base_acq = qKnowledgeGradient(\n",
    "        **base_kwargs,\n",
    "        num_fantasies=mc_samples,\n",
    "        objective=IdentityMCObjective(),\n",
    "        inner_sampler=inner_sampler,\n",
    "    )\n",
    "\n",
    "    \n",
    "conf_name = 'qCUCB'\n",
    "conformal_kwargs = dict(\n",
    "    alpha=1. / math.sqrt(train_inputs.size(0)),\n",
    "    temp=1e-4,\n",
    "    grid_res=mc_samples,\n",
    "    max_grid_refinements=0,\n",
    "    ratio_estimator=None,\n",
    "    grid_sampler=IIDNormalSampler(\n",
    "        mc_samples, collapse_batch_dims=collapse_batch_dims\n",
    "    )\n",
    "#     grid_sampler = SobolQMCNormalSampler(grid_res)\n",
    ")\n",
    "\n",
    "if conf_name == 'qCEI':\n",
    "    conf_acq = qConformalExpectedImprovement(\n",
    "        **conformal_kwargs,\n",
    "        **base_kwargs,\n",
    "        best_f=f[perm][:4].max(),\n",
    "    )\n",
    "elif conf_name == 'qCNEI':\n",
    "    conf_acq = qConformalNoisyExpectedImprovement(\n",
    "        **conformal_kwargs,\n",
    "        **base_kwargs,\n",
    "        X_baseline=train_inputs,\n",
    "    )\n",
    "elif conf_name == 'qCUCB':\n",
    "    conf_acq = qConformalUpperConfidenceBound(\n",
    "        **conformal_kwargs,\n",
    "        optimistic=True,\n",
    "        **base_kwargs,\n",
    "        beta=1.,\n",
    "    )\n",
    "elif conf_name == 'qCKG':\n",
    "    conf_acq = qConformalKnowledgeGradient(\n",
    "        **conformal_kwargs,\n",
    "        model=matern_gp,\n",
    "#         sampler=IIDNormalSampler(mc_samples, batch_range=(0, -3)),\n",
    "        num_fantasies=mc_samples,\n",
    "        objective=IdentityMCObjective(),\n",
    "        inner_sampler=IIDNormalSampler(2 * mc_samples, collapse_batch_dims=collapse_batch_dims),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a7e11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples = 1\n",
    "base_acq_vals = 0.\n",
    "conf_acq_vals = 0.\n",
    "for _ in range(num_samples):\n",
    "#     with torch.no_grad():\n",
    "#         base_acq_vals += base_acq(x_grid[..., None]) / num_samples\n",
    "#         conf_acq_vals += conf_acq(x_grid[..., None]) / num_samples\n",
    "#     bounds = torch.tensor([[0.], [1.]]).to(x_grid)\n",
    "    base_acq_vals += base_acq(kg_inputs) / num_samples\n",
    "    conf_acq_vals += conf_acq(kg_inputs) / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "\n",
    "# ax = plt.axes(projection='3d')\n",
    "# ax.plot_surface(x1.cpu(), x2.cpu(), z.cpu())\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_title(base_name)\n",
    "ax.set_xlabel(r'$x_1$')\n",
    "ax.set_ylabel(r'$x_2$', rotation=0)\n",
    "z = base_acq_vals.reshape(q_grid_res, q_grid_res)\n",
    "contour_kwargs = dict()\n",
    "#     vmin=0,\n",
    "#     vmax=0.06,\n",
    "# )\n",
    "cbar = ax.contourf(x1.cpu(), x2.cpu(), z.cpu(), **contour_kwargs)\n",
    "plt.plot(\n",
    "    np.linspace(0, 1, q_grid_res), np.linspace(0, 1, q_grid_res),\n",
    "    linestyle='--', color='black', linewidth=2\n",
    ")\n",
    "fig.colorbar(cbar)\n",
    "\n",
    "\n",
    "# ax = fig.add_subplot(1, 2, 2)\n",
    "# ax.set_title(conf_name)\n",
    "# ax.set_xlabel(r'$x_1$')\n",
    "# ax.set_ylabel(r'$x_2$', rotation=0)\n",
    "# z = conf_acq_vals.reshape(q_grid_res, q_grid_res)\n",
    "# cbar = ax.contourf(x1.cpu(), x2.cpu(), z.cpu(), **contour_kwargs)\n",
    "# plt.plot(\n",
    "#     np.linspace(0, 1, q_grid_res), np.linspace(0, 1, q_grid_res),\n",
    "#     linestyle='--', color='black', linewidth=2\n",
    "# )\n",
    "# fig.colorbar(cbar)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f793feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_inputs.cpu(), train_targets.cpu(), color='black')\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$y$', rotation=0)\n",
    "plt.xlim((-0.1, 1.1))\n",
    "plt.ylim((-0.1, 1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conformalbo.ratio_estimation import RatioEstimator, optimize_acqf_sgld\n",
    "\n",
    "def run_datashift_opt(seed, acqf=\"ei\"):\n",
    "    def draw_plot(ax):\n",
    "        std_scale = stats.norm.ppf(1 - alpha / 2.)\n",
    "        # plot p(f | x, D)\n",
    "        ax.plot(grid_inputs.cpu(), y_hat_mean, color='blue', linewidth=1, zorder=4)\n",
    "        ax.fill_between(\n",
    "            grid_inputs.view(-1).cpu(),\n",
    "            y_hat_mean - std_scale * f_hat_std,\n",
    "            y_hat_mean + std_scale * f_hat_std,\n",
    "            color='blue', alpha=0.25,\n",
    "            label=r'$p(f | x, \\mathcal{D})$',\n",
    "        )\n",
    "        \n",
    "        # plot C_\\alpha(x)\n",
    "#         ax.plot(all_inputs.view(-1).cpu(), grid_lb.view(-1).cpu(), color='blueviolet', linestyle='--')\n",
    "#         ax.plot(all_inputs.view(-1).cpu(), grid_ub.view(-1).cpu(), color='blueviolet', linestyle='--')\n",
    "        ax.fill_between(grid_inputs.view(-1).cpu(), grid_lb.view(-1).cpu(), grid_ub.view(-1).cpu(),\n",
    "                       color='blueviolet', alpha=0.125)\n",
    "        ax.fill_between(grid_inputs.view(-1).cpu(), conf_lb.view(-1).cpu(), conf_ub.view(-1).cpu(),\n",
    "                       color='blueviolet', alpha=0.25, label=r'$\\mathcal{C}_\\alpha(x)$')\n",
    "#         grid_sample_x = grid_inputs.expand(-1, grid_res).cpu().view(-1)\n",
    "#         grid_sample_y = target_grid.contiguous().cpu().view(-1)\n",
    "#         grid_sample_alpha = conf_pred_mask.cpu().view(-1)\n",
    "#         ax.scatter(grid_sample_x, grid_sample_y, s=8, alpha=grid_sample_alpha, color='blueviolet', marker='+')\n",
    "\n",
    "        # plot a(x)\n",
    "        ax.plot(grid_inputs.cpu(), acq_vals.cpu(), color='green', zorder=5, linewidth=2, label=r'$a(x)$')\n",
    "        ax.scatter(input_query.cpu(), target_query.cpu(), marker='x', color='red', zorder=5,\n",
    "                   s=32, linewidth=2)\n",
    "        ax.scatter(opt_x.cpu().view(-1), opt_y.cpu().view(-1), marker='x', color='red', zorder=5,\n",
    "                   s=16, linewidth=1)\n",
    "\n",
    "        # plot observed\n",
    "        ax.scatter(all_inputs.cpu(), all_targets.cpu(), edgecolors='black', facecolors='black', s=32, zorder=3)\n",
    "#         ax.scatter(val_inputs.cpu(), val_targets.cpu(), edgecolors='black', facecolors='none', s=32, zorder=3)\n",
    "\n",
    "        # plot true function\n",
    "        ax.plot(grid_inputs.cpu(), y_norm(grid_f), color='black', linestyle='--')\n",
    "\n",
    "        ax.set_ylim((-2.1, 2.1))\n",
    "\n",
    "        ax.set_xlabel(r'$x$')\n",
    "        ax.set_ylabel(r'$y$', rotation=0)\n",
    "        \n",
    "        #plot r(x)\n",
    "        if density_ratio is not None:\n",
    "            ax_2 = ax.twinx()\n",
    "            ax_2.plot(grid_inputs.cpu(), density_ratio.log(), color='darkorange', zorder=6, linewidth=2, label='r(x)')\n",
    "            ax_2.set_ylabel(r'$\\log r(x)$', color='darkorange')\n",
    "            ax_2.tick_params(axis='y', labelcolor='darkorange')\n",
    "#         ax.legend(ncol=2, loc='lower center')\n",
    "#         ax.set_title(f't={round_idx}, alpha={alpha:0.2f}')\n",
    "        return ax\n",
    "\n",
    "    print(f\"seed: {seed}\")\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    grid_x = np.linspace(*x_bounds, 64)\n",
    "    grid_f = obj_fn(grid_x)\n",
    "    grid_y = grid_f + noise_scale * np.random.randn(*grid_f.shape)\n",
    "    \n",
    "    cutoff = np.max(np.where(grid_x < -8))\n",
    "    x_min, y_min = grid_x.min(0), grid_y.min(0)\n",
    "    x_range, y_range = grid_x.max(0) - x_min, grid_y.max(0) - y_min\n",
    "\n",
    "    x_norm = Normalizer(\n",
    "        loc=x_min + 0.5 * x_range,\n",
    "        scale=x_range / 2.,\n",
    "    )\n",
    "    y_norm = Normalizer(\n",
    "        loc=y_min + 0.5 * y_range,\n",
    "        scale=y_range / 2.,\n",
    "    )\n",
    "\n",
    "#     train_x = x[:cutoff]\n",
    "#     train_y = y[:cutoff]\n",
    "\n",
    "    grid_inputs = torch.tensor(x_norm(grid_x), device=DEVICE, dtype=dtype).view(-1, 1)\n",
    "    grid_targets = torch.tensor(y_norm(grid_y), device=DEVICE, dtype=dtype).view(-1, 1)\n",
    "    \n",
    "    all_inputs = grid_inputs[:cutoff]\n",
    "    all_targets = grid_targets[:cutoff]\n",
    "\n",
    "#     new_split = DataSplit(\n",
    "#     all_inputs[:cutoff].cpu().numpy(), all_targets[:cutoff].cpu().numpy()\n",
    "#     )\n",
    "#     train_split, val_split, test_split = update_splits(\n",
    "#         train_split=DataSplit(),\n",
    "#         val_split=DataSplit(),\n",
    "#         test_split=DataSplit(),\n",
    "#         new_split=new_split,\n",
    "#         holdout_ratio=0.2\n",
    "#     )\n",
    "#     train_split, val_split, test_split = splits\n",
    "    \n",
    "    rx_estimator = None\n",
    "    optimize_callback = None\n",
    "    \n",
    "    conformal_kwargs = dict(\n",
    "        alpha=None,\n",
    "        temp=temp,\n",
    "        grid_res=grid_res,\n",
    "        max_grid_refinements=max_grid_refinements,\n",
    "        ratio_estimator=rx_estimator,\n",
    "    )\n",
    "\n",
    "#     sampler = SobolQMCNormalSampler(mc_samples)\n",
    "    sampler = IIDNormalSampler(mc_samples)\n",
    "    if acqf == 'ei':\n",
    "        acqf_init = lambda gp, best_f: qExpectedImprovement(\n",
    "            gp,\n",
    "            best_f=output_dict['norm_f_queries'][round_idx],\n",
    "            sampler=sampler\n",
    "        )\n",
    "    elif acqf == \"nei\":\n",
    "        acqf_init = lambda gp, best_f: qNoisyExpectedImprovement(\n",
    "            gp, X_baseline=all_inputs, sampler=sampler, prune_baseline=True\n",
    "        )\n",
    "    elif acqf == \"ucb\":\n",
    "        acqf_init = lambda gp, best_f: UpperConfidenceBound(gp, beta=1.)\n",
    "    elif acqf == \"kg\":\n",
    "        acqf_init = lambda gp, best_f: qKnowledgeGradient(\n",
    "            model=gp,\n",
    "            current_value=output_dict['norm_f_queries'][round_idx],\n",
    "            num_fantasies=None,\n",
    "            sampler=sampler,\n",
    "        )\n",
    "    elif acqf == 'conformal_ei':\n",
    "        def acqf_init(gp, best_f):\n",
    "            acqf = qConformalExpectedImprovement(**conformal_kwargs, model=gp, sampler=sampler,\n",
    "                                                 ratio_estimator=rx_estimator)\n",
    "            return acqf\n",
    "    elif acqf == \"conformal_nei\":\n",
    "        def acqf_init(gp, best_f):\n",
    "            acqf = qConformalNoisyExpectedImprovement(**conformal_kwargs, model=gp, sampler=sampler,\n",
    "                                                      ratio_estimator=rx_estimator)\n",
    "            return acqf\n",
    "    elif acqf == \"conformal_ucb\":\n",
    "        def acqf_init(gp, best_f):\n",
    "            acqf = qConformalUpperConfidenceBound(**conformal_kwargs, model=gp, beta=1., sampler=sampler)\n",
    "            return acqf\n",
    "    elif acqf == \"conformal_kg\":\n",
    "        def acqf_init(gp, best_f):\n",
    "            acqf = qConformalKnowledgeGradient(\n",
    "                **conformal_kwargs,\n",
    "                model=gp,\n",
    "                current_value=None,\n",
    "                num_fantasies=None,\n",
    "                sampler=sampler,\n",
    "            )\n",
    "            return acqf\n",
    "            \n",
    "    \n",
    "    output_dict = {\n",
    "        'f_queries': torch.empty(num_rounds + 1),\n",
    "        'norm_f_queries': torch.empty(num_rounds + 1),\n",
    "        'cred_cvrg': torch.empty(num_rounds),\n",
    "        'conf_cvrg': torch.empty(num_rounds),\n",
    "        'alpha': torch.empty(num_rounds),\n",
    "    }\n",
    "    output_dict['f_queries'][0] = grid_f[:cutoff].max().item()\n",
    "    output_dict['norm_f_queries'][0] = y_norm(grid_f[:cutoff].max()).item()\n",
    "    \n",
    "    for round_idx in range(num_rounds):\n",
    "        perm = np.random.permutation(np.arange(all_inputs.size(0)))\n",
    "        num_test = math.ceil(0.2 * all_inputs.size(0))\n",
    "        num_train = all_inputs.size(0) - num_test\n",
    "#         print(f\"train: {num_train}, test: {num_test}\")\n",
    "\n",
    "        val_inputs, val_targets = all_inputs[perm][:num_test], all_targets[perm][:num_test]\n",
    "        train_inputs, train_targets = all_inputs[perm][num_test:], all_targets[perm][num_test:]\n",
    "                   \n",
    "        alpha = 1 / math.sqrt(train_inputs.size(0))\n",
    "\n",
    "        # fit GP only to train split\n",
    "        matern_gp = SingleTaskGP(\n",
    "            train_X=train_inputs,\n",
    "            train_Y=train_targets,\n",
    "            likelihood=GaussianLikelihood(noise_constraint=Interval(5e-2, 0.5)),\n",
    "        ).to(DEVICE)\n",
    "        mll = ExactMarginalLogLikelihood(matern_gp.likelihood, matern_gp)\n",
    "        fit_gpytorch_model(mll)\n",
    "        matern_gp.requires_grad_(False)\n",
    "        \n",
    "        # assess coverage\n",
    "        matern_gp.eval()\n",
    "        with torch.no_grad():\n",
    "            cred_cvrg, conf_cvrg = assess_coverage(\n",
    "                matern_gp, val_inputs, val_targets, alpha, temp=1e-6,\n",
    "                grid_res=grid_res, max_grid_refinements=4\n",
    "            )\n",
    "        \n",
    "        # fit GP to all data\n",
    "        matern_gp = SingleTaskGP(\n",
    "            train_X=all_inputs,\n",
    "            train_Y=all_targets,\n",
    "            likelihood=GaussianLikelihood(noise_constraint=Interval(5e-2, 0.2)),\n",
    "        ).to(DEVICE)\n",
    "        mll = ExactMarginalLogLikelihood(matern_gp.likelihood, matern_gp)\n",
    "        fit_gpytorch_model(mll)\n",
    "        matern_gp.requires_grad_(False)\n",
    "        \n",
    "        # prepare ratio estimator\n",
    "        if acqf.startswith('conformal_'):\n",
    "            rx_estimator = RatioEstimator(in_size=all_inputs.shape[-1], device=DEVICE, dtype=dtype)\n",
    "            optimize_callback = rx_estimator.optimize_callback\n",
    "            rx_estimator.dataset._update_splits(\n",
    "                DataSplit(all_inputs.view(-1, 1).cpu(), torch.zeros(all_inputs.size(0), 1))\n",
    "            )\n",
    "        \n",
    "        alpha = 1 / math.sqrt(all_inputs.size(0))\n",
    "        conformal_kwargs['alpha'] = alpha\n",
    "        \n",
    "        # get next point\n",
    "        acq_fn = acqf_init(matern_gp, train_targets.max())\n",
    "        if acqf.startswith('conformal_'):\n",
    "            opt_x, opt_y = optimize_acqf_sgld(acq_fn, input_bounds, batch_size, num_restarts=num_restarts, raw_samples=mc_samples,\n",
    "                                        options=dict(callback=optimize_callback, disp=False, ftol=1e-12),\n",
    "                                        return_best_only=False)\n",
    "        else:\n",
    "            opt_x, opt_y = optimize_acqf(acq_fn, input_bounds, batch_size, num_restarts=num_restarts, raw_samples=mc_samples,\n",
    "                                        options=dict(callback=optimize_callback, disp=False, ftol=1e-12),\n",
    "                                        return_best_only=False)\n",
    "        \n",
    "        input_query = opt_x.flatten(0, -3)[opt_y.flatten().argmax()]\n",
    "        x_query = x_norm.inv_transform(input_query.detach().cpu().numpy())\n",
    "        f_query = obj_fn(x_query)\n",
    "        y_query = f_query + noise_scale * np.random.randn(*f_query.shape)\n",
    "        target_query = torch.tensor(y_norm(y_query), device=DEVICE, dtype=dtype)\n",
    "        \n",
    "        all_inputs = torch.cat([all_inputs, input_query.reshape(-1, 1)])\n",
    "        all_targets = torch.cat([all_targets, target_query.reshape(-1, 1)])\n",
    "        \n",
    "#         all_inputs, idxs = torch.sort(all_inputs, dim=0)\n",
    "#         all_targets = all_targets[idxs.squeeze(-1)]\n",
    "        \n",
    "        # log result\n",
    "        output_dict['f_queries'][round_idx + 1] = f_query.max().item()\n",
    "        output_dict['norm_f_queries'][round_idx + 1] = y_norm(f_query.max()).item()\n",
    "        output_dict['cred_cvrg'][round_idx] = cred_cvrg\n",
    "        output_dict['conf_cvrg'][round_idx] = conf_cvrg\n",
    "        output_dict['alpha'][round_idx] = alpha\n",
    "        \n",
    "        density_ratio = None\n",
    "        if rx_estimator is not None:\n",
    "            density_ratio = rx_estimator(grid_inputs).cpu()\n",
    "#             log_imp_weights = (density_ratio / density_ratio.sum()).log()\n",
    "            \n",
    "#         if acqf.startswith('conformal_'):\n",
    "#             rx_estimator.dataset._update_splits(\n",
    "#                 DataSplit(input_query.reshape(-1, 1).cpu(), torch.ones(1, 1)))\n",
    "\n",
    "        # try drawing a plot\n",
    "        if (round_idx + 1) % plot_interval == 0:\n",
    "            print(f'GP noise: {matern_gp.likelihood.noise.item():0.4f}')\n",
    "#             try:\n",
    "            with torch.no_grad():\n",
    "                f_hat_dist = matern_gp(grid_inputs)\n",
    "                y_hat_dist = matern_gp.likelihood(f_hat_dist)\n",
    "                f_hat_mean = f_hat_dist.mean.cpu()\n",
    "                f_hat_std = f_hat_dist.variance.sqrt().cpu()\n",
    "                y_hat_mean = f_hat_mean.cpu()\n",
    "                y_hat_std = y_hat_dist.variance.sqrt().cpu()\n",
    "                acq_vals = acq_fn(grid_inputs[:, None])\n",
    "                grid_sampler = IIDNormalSampler(\n",
    "                    grid_res, resample=False, collapse_batch_dims=True\n",
    "                )\n",
    "#                     grid_sampler = IIDNormalSampler(grid_res, resample=True)\n",
    "                target_grid, _, conf_pred_mask, _ = construct_conformal_bands(\n",
    "                    matern_gp, grid_inputs[:, None], alpha, temp=1e-6,\n",
    "                    grid_res=grid_res, max_grid_refinements=4, sampler=grid_sampler,\n",
    "                    ratio_estimator=rx_estimator\n",
    "                )\n",
    "                grid_lb = target_grid.min(-3)[0]\n",
    "                grid_ub = target_grid.max(-3)[0]\n",
    "                conf_lb, conf_ub = conf_mask_to_bounds(target_grid, conf_pred_mask)\n",
    "\n",
    "            if rx_estimator is not None:\n",
    "                print(f'[Iterates] {rx_estimator.dataset.cls_train_split[0].shape[0]} train, {rx_estimator.dataset.cls_val_split[0].shape[0]} val, {rx_estimator.dataset.cls_test_split[0].shape[0]} test')\n",
    "            fig = plt.figure(figsize=(6, 5))\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            draw_plot(ax)\n",
    "            plt.tight_layout()\n",
    "            if save_figs:\n",
    "                plt.savefig(f'./figures/synth-example_prediction-sets_seed-{seed}_round-{round_idx}.pdf')\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "#                 continue\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce882e1",
   "metadata": {},
   "source": [
    "### Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 4\n",
    "mc_samples = 32\n",
    "grid_res = 128\n",
    "temp = 0.25\n",
    "max_grid_refinements = 0\n",
    "num_rounds = 16\n",
    "num_restarts = 8\n",
    "batch_size = 1\n",
    "plot_interval = 4\n",
    "save_figs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f91447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conformal_out = [\n",
    "    run_datashift_opt(\n",
    "        seed, acqf=\"conformal_ucb\"\n",
    "    ) for seed in range(num_trials)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf145d04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "std_out = [\n",
    "    run_datashift_opt(\n",
    "        seed, acqf=\"ucb\"\n",
    "    ) for seed in range(num_trials)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "conf_best_f = torch.stack([d['f_queries'] for d in conformal_out]).cummax(1)[0]\n",
    "std_best_f = torch.stack([d['f_queries'] for d in std_out]).cummax(1)[0]\n",
    "\n",
    "plt.plot(conf_best_f.quantile(0.5, dim=0), label = \"qUCB\", color='blueviolet', linewidth=4, zorder=3)\n",
    "plt.fill_between(torch.arange(conf_best_f.size(-1)), \n",
    "                 conf_best_f.quantile(0.2, dim=0), \n",
    "                 conf_best_f.quantile(0.8, dim=0), \n",
    "                 alpha = 0.25, color='blueviolet')\n",
    "plt.plot(std_best_f.quantile(0.5, dim=0), label = \"qCUCB\", color='blue', linewidth=4, zorder=2)\n",
    "plt.fill_between(torch.arange(std_best_f.size(-1)), \n",
    "                 std_best_f.quantile(0.2, dim=0), \n",
    "                 std_best_f.quantile(0.8, dim=0), \n",
    "                 alpha = 0.25, color='blue')\n",
    "\n",
    "plt.xlim(plt.xlim())\n",
    "plt.hlines(32., *plt.xlim(), linestyle='--', color='black', linewidth=4, label=r'$f(x^*)$', zorder=1)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Function Evaluations\")\n",
    "plt.ylabel(r\"Best $f$ Achieved\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/synth-example_best-f.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30d6f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "conf_cvrg = torch.stack([d['conf_cvrg'] for d in conformal_out])\n",
    "cred_cvrg = torch.stack([d['cred_cvrg'] for d in conformal_out])\n",
    "alpha = torch.stack([d['alpha'] for d in conformal_out])\n",
    "\n",
    "plt.plot(conf_cvrg.quantile(0.5, dim=0), label = \"conformal\", color='blueviolet', linewidth=4, zorder=3)\n",
    "# plt.fill_between(torch.arange(conf_cvrg.size(-1)), \n",
    "#                  conf_cvrg.quantile(0.2, dim=0), \n",
    "#                  conf_cvrg.quantile(0.8, dim=0), \n",
    "#                  alpha = 0.25, color='blueviolet')\n",
    "plt.plot(cred_cvrg.quantile(0.5, dim=0), label = \"credible\", color='blue', linewidth=4, zorder=2)\n",
    "# plt.fill_between(torch.arange(conf_cvrg.size(-1)), \n",
    "#                  cred_cvrg.quantile(0.2, dim=0), \n",
    "#                  cred_cvrg.quantile(0.8, dim=0), \n",
    "#                  alpha = 0.25, color='blue')\n",
    "\n",
    "cov_lb = 1 - alpha + 1 / (1 / alpha ** 2 + 1)\n",
    "cov_ub = 1 - alpha - 1 / (1 / alpha ** 2 + 1)\n",
    "plt.plot(torch.arange(alpha.size(-1)), cov_lb.mean(0),\n",
    "         color='black', linestyle='dotted', linewidth=2)\n",
    "plt.plot(torch.arange(alpha.size(-1)), cov_ub.mean(0),\n",
    "         color='black', linestyle='dotted', linewidth=2)\n",
    "plt.plot(torch.arange(alpha.size(-1)), (1 - alpha).mean(0),\n",
    "         color='black', linestyle='--', linewidth=4, label=r'$1 - \\alpha$', zorder=1)\n",
    "\n",
    "plt.legend(ncol=1, loc='lower right')\n",
    "plt.xlabel(\"Function Evaluations\")\n",
    "plt.ylabel(\"Emp. Coverage\")\n",
    "plt.ylim((-0.1, 1.1))\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/synth-example_emp-cvrg.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "t = np.arange(1, 1000).astype(float)\n",
    "plt.plot(t, t, label=r'$t$', linewidth=4)\n",
    "plt.plot(t, (t * np.log(t) ** 2) ** 0.5, label=r'$\\sqrt{t\\log^2 t}$', linewidth=4)\n",
    "plt.plot(t, t ** 0.5, label=r'$\\sqrt{t}$', linewidth=4)\n",
    "plt.xlabel(r'$t$')\n",
    "# plt.legend(ncol=3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629070b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee76cd046ae11036d20cc0a4495049efefd62bb2bb494c5d62c8b14f5cf253b7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
