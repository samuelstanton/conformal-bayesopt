{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.distributions import Normal\n",
    "\n",
    "sns.set(font_scale=2., style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, n, n_pos=None):\n",
    "        self.p1 = Normal(torch.tensor(0.), torch.tensor(1))\n",
    "        self.p2 = Normal(torch.tensor(-1.), torch.tensor(2))\n",
    "\n",
    "        self.n_pos = n_pos if n_pos is not None else n // 2\n",
    "\n",
    "        self.inputs = torch.cat([\n",
    "            self.p1.sample(torch.Size([self.n_pos, 1])),\n",
    "            self.p2.sample(torch.Size([n - self.n_pos, 1]))\n",
    "        ])\n",
    "        self.targets = torch.cat([\n",
    "            torch.ones(self.n_pos),\n",
    "            torch.zeros(n - self.n_pos),\n",
    "        ])\n",
    "\n",
    "    def log_ratio(self, x):\n",
    "        return self.p1.log_prob(x) - self.p2.log_prob(x)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "dataset = ToyDataset(n=200, n_pos=20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "_n = len(dataset) // 2\n",
    "x = torch.linspace(-5, 5, 1000)\n",
    "ax.plot(x, dataset.p1.log_prob(x).exp(), c='green', label=r'$\\mathcal{N}(1, 1)$')\n",
    "ax.scatter(dataset.inputs[:_n], torch.zeros_like(dataset.inputs[:_n]), c='green', alpha=.1)\n",
    "\n",
    "ax.plot(x, dataset.p2.log_prob(x).exp(), c='blue', label=r'$\\mathcal{N}(0, 2^2)$')\n",
    "ax.scatter(dataset.inputs[_n:], torch.zeros_like(dataset.inputs[_n:]), c='blue', alpha=.1)\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cuda:7'\n",
    "\n",
    "class RatioEstimator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.classifier(inputs)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ratio(self, inputs, n=None, n_pos=None):\n",
    "        p = self(inputs).squeeze(-1).sigmoid()\n",
    "        prior_ratio = 1.\n",
    "        if n is not None and n_pos is not None:\n",
    "            prior_ratio = self.n / self.n_pos - 1\n",
    "        \n",
    "        return (prior_ratio * p) / (1 - p)\n",
    "\n",
    "estimator = RatioEstimator().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(len(dataset) / dataset.n_pos - 1))\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.Adam(estimator.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "def plot_rx(title=None):\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "    ax.plot(x, dataset.log_ratio(x).exp(), c='blue', label=r'$r(x)$')\n",
    "    ax.plot(x, estimator.ratio(x.unsqueeze(-1).to(device)).cpu(), c='red', label=r'$\\widehat{r}(x)$')\n",
    "    ax.set(title=title)\n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "\n",
    "for e in tqdm(range(200), leave=False):\n",
    "    for X, y in DataLoader(dataset, batch_size=64, shuffle=True):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optim.zero_grad()\n",
    "        loss = criterion(estimator(X).squeeze(-1), y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    if e % 10 == 0:\n",
    "        plot_rx(title=rf'Epoch ${e}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rx()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee76cd046ae11036d20cc0a4495049efefd62bb2bb494c5d62c8b14f5cf253b7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('conformal-bayesopt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
