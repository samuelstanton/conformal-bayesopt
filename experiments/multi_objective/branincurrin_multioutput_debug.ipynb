{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7056748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from botorch.acquisition.objective import ConstrainedMCObjective\n",
    "from botorch.acquisition.monte_carlo import (\n",
    "    qExpectedImprovement,\n",
    "    qNoisyExpectedImprovement,\n",
    ")\n",
    "from botorch.acquisition.knowledge_gradient import qKnowledgeGradient\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../conformalbo/\")\n",
    "from utils import (\n",
    "    generate_initial_data,\n",
    "    initialize_model,\n",
    "    parse,\n",
    "    optimize_acqf_and_get_observation,\n",
    "    update_random_observations,\n",
    "    get_problem,\n",
    "    # assess_coverage,\n",
    ")\n",
    "# from helpers import qConformalExpectedImprovement, qConformalNoisyExpectedImprovement\n",
    "from botorch.models.transforms import Standardize, Normalize\n",
    "\n",
    "from botorch.test_functions.multi_objective import BraninCurrin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a251634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wesley_m  9332  1.0  0.0  12896  3052 pts/53   Ss+  13:21   0:00 /bin/bash -c ps aux | grep 14090\r\n",
      "wesley_m  9334  0.0  0.0  14440  1124 pts/53   S+   13:21   0:00 grep 14090\r\n",
      "sanae_l  14090  100  0.5 16587380 2965756 pts/88 Rl 05:20 481:35 python experiments/compute_bound.py --dataset=fmnist --encoding_type=arithmetic --levels=20 --misc_extra_bits=3 --prenet_cfg_path=/data/users/sanyam_s/assets/pactl/sweep-bu6bb4px/run-20220502-6wh95170/files/net.cfg.yml --scale_posterior=0.01 --use_kmeans=0\r\n"
     ]
    }
   ],
   "source": [
    "!ps aux | grep 14090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb409fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  4 13:21:07 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    On   | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 41%   29C    P8    11W / 280W |   5295MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN RTX    On   | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 56%   75C    P2   280W / 280W |   7059MiB / 24220MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA TITAN RTX    On   | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 41%   22C    P8     5W / 280W |   6716MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA TITAN RTX    On   | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 41%   28C    P8    31W / 280W |   7458MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA TITAN RTX    On   | 00000000:88:00.0 Off |                  N/A |\n",
      "| 54%   74C    P2   286W / 280W |   3180MiB / 24220MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA TITAN RTX    On   | 00000000:89:00.0 Off |                  N/A |\n",
      "| 41%   29C    P8    21W / 280W |   6674MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA TITAN RTX    On   | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 61%   80C    P2   263W / 280W |  15313MiB / 24220MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA TITAN RTX    On   | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 41%   32C    P2    85W / 280W |   5421MiB / 24220MiB |     14%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     14090      C   python                           1323MiB |\n",
      "|    0   N/A  N/A     23758      C   python                           1323MiB |\n",
      "|    0   N/A  N/A     32261      C   python                           1323MiB |\n",
      "|    0   N/A  N/A     48331      C   python                           1323MiB |\n",
      "|    1   N/A  N/A      9645      C   .../envs/cloneart/bin/python     3929MiB |\n",
      "|    1   N/A  N/A     15728      C   ...nda3/envs/py38/bin/python     3127MiB |\n",
      "|    2   N/A  N/A      9644      C   .../envs/cloneart/bin/python     1421MiB |\n",
      "|    2   N/A  N/A     20536      C   python                           1323MiB |\n",
      "|    2   N/A  N/A     21239      C   python                           1323MiB |\n",
      "|    2   N/A  N/A     32551      C   python                           1323MiB |\n",
      "|    2   N/A  N/A     63525      C   python                           1323MiB |\n",
      "|    3   N/A  N/A      4076      C   ...an_y/miniconda/bin/python     4295MiB |\n",
      "|    3   N/A  N/A      9646      C   .../envs/cloneart/bin/python     1453MiB |\n",
      "|    3   N/A  N/A     54750      C   ...an_y/miniconda/bin/python     1705MiB |\n",
      "|    4   N/A  N/A      9643      C   .../envs/cloneart/bin/python     3177MiB |\n",
      "|    5   N/A  N/A      2697      C   python                           1323MiB |\n",
      "|    5   N/A  N/A      9641      C   .../envs/cloneart/bin/python     1383MiB |\n",
      "|    5   N/A  N/A     41542      C   python                           1321MiB |\n",
      "|    5   N/A  N/A     49154      C   python                           1321MiB |\n",
      "|    5   N/A  N/A     52567      C   python                           1321MiB |\n",
      "|    6   N/A  N/A      9642      C   .../envs/cloneart/bin/python     1421MiB |\n",
      "|    6   N/A  N/A     45161      C   python3                         13889MiB |\n",
      "|    7   N/A  N/A      2303      C   python                           1321MiB |\n",
      "|    7   N/A  N/A      3808      C   python                           1323MiB |\n",
      "|    7   N/A  N/A      8080      C   python                           1451MiB |\n",
      "|    7   N/A  N/A     64618      C   python                           1323MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bcc6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.double# if dtype == \"double\" else torch.float\n",
    "device = torch.device(\"cuda:5\")\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "bb_fn = BraninCurrin(negate=True).to(device,dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138b7b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 2]) torch.Size([30, 2])\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "        train_x_ei,\n",
    "        train_obj_ei,\n",
    "        best_observed_value_ei,\n",
    "    ) = generate_initial_data(\n",
    "        30, bb_fn, 0.1, device, dtype\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7277699",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = train_obj_ei.mean(0), train_obj_ei.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8efb09eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_ei = (train_obj_ei - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5a0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yvar = torch.tensor(0.3 ** 2, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da06817c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_obj_ei.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de7a8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "mll_and_model = initialize_model(\n",
    "            train_x_ei, train_obj_ei.squeeze(), train_yvar,\n",
    "            method=\"exact\", alpha=0.05, tgt_grid_res=64,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "905c886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2]) torch.Size([100, 2])\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "        val_x,\n",
    "        val_obj,\n",
    "        _,\n",
    "    ) = generate_initial_data(\n",
    "        100, bb_fn, 0.1, device, dtype\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d20f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_obj = (val_obj - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fb82c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_gpytorch_model(mll_and_model[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cd9f5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9764bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import assess_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f6d3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_kwargs = dict(\n",
    "                alpha=0.2,\n",
    "                grid_res=32,\n",
    "                max_grid_refinements=4,\n",
    "                ratio_estimator=None,\n",
    "    temp=0.01,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5d4edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mll_and_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac72a252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25e862d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.posterior(val_x.unsqueeze(-2)).mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8aae69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_inputs = torch.rand(100, 1, 2, device=device, dtype=dtype)\n",
    "# target_grid = torch.randn(100, 32, 1, 2, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ac63f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import est_train_post_var, conformal_gp_regression\n",
    "import torchsort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f91d1f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesley_m/gpytorch/gpytorch/lazy/lazy_tensor.py:1810: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n"
     ]
    }
   ],
   "source": [
    "cred_bounds, conf_bounds = assess_coverage(mll_and_model[1], val_x, val_obj, **conformal_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18920650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6549999713897705"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd95383",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_val_y = mll_and_model[2](val_obj)[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.vlines(trans_val_y, cred_bounds[0].cpu(), cred_bounds[1].cpu(), alpha = 0.2)\n",
    "plt.scatter(trans_val_y, (cred_bounds[0] + cred_bounds[1]).cpu() / 2, label = \"Credible\")\n",
    "plt.vlines(trans_val_y, conf_bounds[0].cpu(), conf_bounds[1].cpu(), color = \"orange\", alpha = 0.2)\n",
    "plt.scatter(trans_val_y, (conf_bounds[0] + conf_bounds[1]).cpu() / 2, label = \"Conformal\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.legend()\n",
    "plt.title(\"Levy-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09204cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((cred_bounds[1] - cred_bounds[0]).cpu().numpy())\n",
    "plt.hist((conf_bounds[1] - conf_bounds[0]).cpu().numpy(), alpha = 0.5)\n",
    "plt.xlabel(\"Width\")\n",
    "plt.title(\"Width of Equivalent Intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec68af",
   "metadata": {},
   "source": [
    "## ignore below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = torch.meshgrid(torch.linspace(0, 1, 40), torch.linspace(0, 1, 40))\n",
    "test_x = torch.stack((xx.reshape(-1), yy.reshape(-1))).t().to(device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb88b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mll, model, trans = mll_and_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959edba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, objective = train_x_ei, train_obj_ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25666c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans.eval()\n",
    "t_objective = trans(objective)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29586164",
   "metadata": {},
   "outputs": [],
   "source": [
    "acqf = qConformalExpectedImprovement(\n",
    "    model=model,\n",
    "    best_f=(t_objective).max(),\n",
    "    sampler=PassSampler(64),\n",
    ")\n",
    "acqf.objective._verify_output_shape = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.conformal()\n",
    "    conformalei = acqf(test_x.unsqueeze(-2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ec6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.standard()\n",
    "acqf = qExpectedImprovement(\n",
    "    model=model,\n",
    "    best_f=(t_objective).max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95247bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    stdei = acqf(test_x.unsqueeze(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.contourf(xx, yy, stdei.cpu().reshape(40,40))\n",
    "plt.colorbar(f)\n",
    "plt.title(\"Standard EI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d65aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.contourf(xx, yy, conformalei.cpu().reshape(40,40))\n",
    "plt.colorbar(f)\n",
    "plt.title(\"Conformal EI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 30\n",
    "batch_size = 1\n",
    "num_init = 10\n",
    "noise_se = 0.1\n",
    "method = \"exact\"\n",
    "alpha = 0.05\n",
    "tgt_grid_res = 64\n",
    "mc_samples = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef97d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"ei\", \"cei\"]\n",
    "best_observed = {k: [] for k in keys}\n",
    "coverage = {k: [] for k in keys}\n",
    "\n",
    "# call helper functions to generate initial training data and initialize model\n",
    "# (\n",
    "#     train_x_ei,\n",
    "#     train_obj_ei,\n",
    "#     best_observed_value_ei,\n",
    "# ) = generate_initial_data(\n",
    "#     num_init, bb_fn, noise_se, device, dtype\n",
    "# )\n",
    "heldout_x, heldout_obj, _ = generate_initial_data(20 * num_init, bb_fn, noise_se, device, dtype)\n",
    "\n",
    "mll_model_dict = {}\n",
    "data_dict = {}\n",
    "for k in keys:\n",
    "    mll_and_model = initialize_model(\n",
    "        train_x_ei, train_obj_ei, train_yvar,\n",
    "        method=method, alpha=alpha, tgt_grid_res=tgt_grid_res,\n",
    "    )\n",
    "    mll_model_dict[k] = (mll_and_model)\n",
    "    best_observed[k].append(best_observed_value_ei)\n",
    "    data_dict[k] = (train_x_ei, train_obj_ei)\n",
    "\n",
    "optimize_acqf_kwargs = {\n",
    "    \"bounds\": bounds,\n",
    "    \"BATCH_SIZE\": batch_size,\n",
    "    \"fn\": bb_fn,\n",
    "    \"noise_se\": noise_se,\n",
    "}\n",
    "\n",
    "# run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "for iteration in range(1, n_batch + 1):\n",
    "    t0 = time.time()\n",
    "    for k in keys:\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if k == \"rnd\":\n",
    "            # update random\n",
    "            best_observed[k] = update_random_observations(batch_size, best_observed[k], bb_fn.bounds, bb_fn, dim=bounds.shape[1])\n",
    "            continue\n",
    "\n",
    "        # fit the model\n",
    "        mll, model, trans = mll_model_dict[k]\n",
    "        inputs, objective = data_dict[k]\n",
    "        trans.eval()\n",
    "        t_objective = trans(objective)[0]\n",
    "        # model.requires_grad_(True)\n",
    "        fit_gpytorch_model(mll)\n",
    "        # model.requires_grad_(False)\n",
    "#         print(list(model.named_parameters()))\n",
    "        # now assess coverage on the heldout set\n",
    "        # TODO: update the heldout sets\n",
    "        coverage[k].append(assess_coverage(model, heldout_x, trans(heldout_obj)[0], alpha))\n",
    "        print(coverage[k][-1], k)\n",
    "\n",
    "        # now prepare the acquisition\n",
    "        qmc_sampler = SobolQMCNormalSampler(num_samples=mc_samples)\n",
    "        if k == \"ei\":\n",
    "            acqf = qExpectedImprovement(\n",
    "                model=model,\n",
    "                best_f=(t_objective).max(),\n",
    "               sampler=qmc_sampler,\n",
    "            )\n",
    "        elif k == \"nei\":\n",
    "            acqf = qNoisyExpectedImprovement(\n",
    "                model=model,\n",
    "                X_baseline=inputs,\n",
    "                sampler=qmc_sampler,\n",
    "            )\n",
    "        elif k == \"kg\":\n",
    "            acqf = qKnowledgeGradient(\n",
    "                model=model,\n",
    "                current_value=t_objective.max(),\n",
    "                num_fantasies=None,\n",
    "                sampler=qmc_sampler,\n",
    "            )\n",
    "        elif k == \"cei\":\n",
    "            model.conformal()\n",
    "            acqf = qConformalExpectedImprovement(\n",
    "                model=model,\n",
    "                best_f=(t_objective).max(),\n",
    "                sampler=PassSampler(mc_samples),\n",
    "            )\n",
    "            acqf.objective._verify_output_shape = False\n",
    "        elif k == \"cnei\":\n",
    "            model.conformal()\n",
    "            acqf = qConformalNoisyExpectedImprovement(\n",
    "                model=model,\n",
    "                X_baseline=inputs,\n",
    "                sampler=PassSampler(mc_samples),\n",
    "                cache_root=False,\n",
    "            )\n",
    "            acqf.objective._verify_output_shape = False\n",
    "        \n",
    "        print(model.train_inputs[0].shape, model.train_targets.shape, 'shapes')\n",
    "        # optimize acquisition\n",
    "        new_x, new_obj = optimize_acqf_and_get_observation(\n",
    "            acqf, **optimize_acqf_kwargs\n",
    "        )\n",
    "        new_x = new_x.detach()\n",
    "    \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = acqf(test_x.unsqueeze(-2)).cpu()\n",
    "            plt.figure()\n",
    "            f = plt.contourf(xx, yy, output.reshape(40, 40))\n",
    "            plt.colorbar(f)\n",
    "        \n",
    "        # display new pt\n",
    "        plt.scatter(new_x[0,0].cpu(), new_x[0,1].cpu(), color = \"red\")\n",
    "        plt.title(k)\n",
    "        plt.show()\n",
    "            \n",
    "        inputs = torch.cat([inputs, new_x])\n",
    "        objective = torch.cat([objective, new_obj])\n",
    "\n",
    "        best_observed[k].append(objective.max().item())\n",
    "        # prepare new model\n",
    "        mll, model, trans = initialize_model(\n",
    "            inputs,\n",
    "            objective,\n",
    "            method=method,\n",
    "        )\n",
    "        mll_model_dict[k] = (mll, model, trans)\n",
    "        data_dict[k] = inputs, objective\n",
    "\n",
    "    t1 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeac26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (16, 5))\n",
    "ax[0].scatter(*data_dict[\"ei\"][0].t().cpu(), c=torch.arange(40))\n",
    "ax[1].scatter(*data_dict[\"cei\"][0].t().cpu(),c=torch.arange(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_dict[\"ei\"][1].cpu().cummax(0)[0])\n",
    "plt.plot(data_dict[\"cei\"][1].cpu().cummax(0)[0])\n",
    "plt.ylim((-20, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeca692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
